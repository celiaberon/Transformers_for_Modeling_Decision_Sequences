{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "from transformer.transformer import DataLoader    \n",
    "from utils.parse_data import load_trained_model\n",
    "project_root = os.path.abspath(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model model_seen9M on cpu  (embedding=4, block_size=6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/corwin/Building/Learning/Transformers_for_Modeling_Decision_Sequences/utils/parse_data.py:426: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "#1.  Load the model that was trained in run_2\n",
    "RUN = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model, model_info, cfg = load_trained_model(\n",
    "    run        = RUN,\n",
    "    model_name = \"model_seen9M\",\n",
    "    device     = device,\n",
    ")\n",
    "print(f\"Loaded model {model_info['model_name']} on {device}  \"\n",
    "      f\"(embedding={cfg.n_embd}, block_size={cfg.block_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in 100000 tokens from /Users/corwin/Building/Learning/Transformers_for_Modeling_Decision_Sequences/experiments/run_2/seqs/behavior_run_2tr.txt\n"
     ]
    }
   ],
   "source": [
    "# 2. Build a dataloader with the same B and T used during training\n",
    "B, T = 300, 6 \n",
    "loader = DataLoader(\n",
    "    B             = B,\n",
    "    T             = T,\n",
    "    process_rank  = 0,\n",
    "    num_processes = 1,\n",
    "    run_number    = RUN,\n",
    "    suffix        = 'tr',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All residual snapshots have sequence length 6: True\n",
      "Total residuals collected: 3000\n",
      "Each residual shape: torch.Size([4, 6])\n"
     ]
    }
   ],
   "source": [
    "# 3. Collect residuals, log-odds, and sequences using passive estimator\n",
    "from synthetic_data_generation.agent import RFLR_mouse\n",
    "\n",
    "N_BATCHES = 10  # collect 3000 sequences\n",
    "all_residuals = []\n",
    "all_passive_logodds = []  # Ground truth log odds from passive estimator\n",
    "all_sequences = []  # store the actual RrLlR sequences\n",
    "\n",
    "# Create an agent instance for passive estimation\n",
    "# You may need to adjust these parameters based on your training setup\n",
    "agent = RFLR_mouse(alpha=0.78, beta=2.05, tau=1.43)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx in range(N_BATCHES):\n",
    "        x, _ = loader.next_batch()\n",
    "        x = x.to(device)\n",
    "\n",
    "        logits, loss, residual = model(x, return_residual=True)\n",
    "        \n",
    "        # Reshape residual from [B, T, n_embd] to [n_embd, T] for each batch\n",
    "        # residual shape: [B, T, n_embd] -> [B, n_embd, T] -> Bx4x6 in our case\n",
    "        residual_reshaped = residual.permute(0, 2, 1)\n",
    "\n",
    "        for b in range(residual_reshaped.size(0)):\n",
    "            all_residuals.append(residual_reshaped[b])            # [4,6]\n",
    "            \n",
    "            # Convert tensor indices back to R/L characters and choices/rewards\n",
    "            vocab = ['R', 'r', 'L', 'l']\n",
    "            itos = {i: ch for i, ch in enumerate(vocab)}\n",
    "            sequence_chars = tuple(itos[int(idx)] for idx in x[b])\n",
    "            all_sequences.append(sequence_chars)               # [6] - actual sequence as chars\n",
    "            \n",
    "            # Convert sequence to choices and rewards for passive estimator\n",
    "            choices = []\n",
    "            rewards = []\n",
    "            for char in sequence_chars:\n",
    "                if char in ['R', 'r']:\n",
    "                    choices.append(1)  # Right choice\n",
    "                    rewards.append(1 if char == 'R' else 0)  # Reward if uppercase\n",
    "                else:  # char in ['L', 'l']\n",
    "                    choices.append(0)  # Left choice  \n",
    "                    rewards.append(1 if char == 'L' else 0)  # Reward if uppercase\n",
    "            \n",
    "            agent = RFLR_mouse(alpha=0.78, beta=2.05, tau=1.43)\n",
    "            \n",
    "            for c, r in zip(choices, rewards):\n",
    "                agent.update_phi(c, r)\n",
    "            \n",
    "            logodds_next = agent.compute_log_odds(choices[-1])\n",
    "            all_passive_logodds.append(logodds_next)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Verify every snapshot is n_embd×6 format\n",
    "# ------------------------------------------------------------------\n",
    "expected_seq_len = 6\n",
    "ok = all(residual.shape[1] == expected_seq_len for residual in all_residuals)\n",
    "print(f\"\\nAll residual snapshots have sequence length {expected_seq_len}:\", ok)\n",
    "print(f\"Total residuals collected: {len(all_residuals)}\")\n",
    "print(f\"Each residual shape: {all_residuals[0].shape if all_residuals else 'None'}\")\n",
    "assert ok, f\"Found a residual whose sequence length ≠ {expected_seq_len}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences collected: 3000\n",
      "Number of unique sequences: 597\n",
      "\n",
      "First 5 unique sequences:\n",
      "Sequence: ('R', 'r', 'r', 'L', 'r', 'r')\n",
      "Residual: tensor([[-0.3820, -0.0530, -0.0497,  0.4367, -0.1079, -0.0750],\n",
      "        [ 0.3729, -0.2439, -0.4258, -0.0364, -0.2951, -0.2367],\n",
      "        [ 1.1575,  0.8633,  0.6045, -0.2724,  0.2323,  0.2203],\n",
      "        [-1.0677, -0.1992,  0.0508, -0.1686,  0.2850,  0.2911]])\n",
      "Log odds: 0.3434194814002114\n",
      "\n",
      "Sequence: ('r', 'r', 'L', 'r', 'r', 'L')\n",
      "Residual: tensor([[ 0.0822,  0.0459,  0.5809, -0.0447, -0.1062,  0.5447],\n",
      "        [-0.3669, -0.4167, -0.2044, -0.2781, -0.2463, -0.1163],\n",
      "        [ 0.6393,  0.5874, -0.3218,  0.2317,  0.1786, -0.5007],\n",
      "        [-0.0878,  0.1738, -0.0481,  0.2683,  0.3029,  0.0870]])\n",
      "Log odds: -3.0740335652556006\n",
      "\n",
      "Sequence: ('r', 'L', 'r', 'r', 'L', 'l')\n",
      "Residual: tensor([[ 0.0822,  0.6799,  0.0083, -0.0493,  0.5220,  0.4793],\n",
      "        [-0.3669, -0.1644, -0.3208, -0.2920, -0.1858,  0.2457],\n",
      "        [ 0.6393, -0.2106,  0.2960,  0.2452, -0.4906, -0.3044],\n",
      "        [-0.0878, -0.1020,  0.2187,  0.2691,  0.0838, -0.1024]])\n",
      "Log odds: -1.9161925136010312\n",
      "\n",
      "Sequence: ('L', 'r', 'r', 'L', 'l', 'L')\n",
      "Residual: tensor([[ 1.0209,  0.1784,  0.0337,  0.6402,  0.4589,  0.5913],\n",
      "        [-0.3786, -0.2169, -0.2585, -0.2939,  0.1947, -0.0948],\n",
      "        [-0.5646,  0.2888,  0.2323, -0.4869, -0.2893, -0.5316],\n",
      "        [ 0.0333,  0.2001,  0.2223,  0.1241, -0.1305,  0.0458]])\n",
      "Log odds: -3.3908234478840944\n",
      "\n",
      "Sequence: ('r', 'r', 'L', 'l', 'L', 'L')\n",
      "Residual: tensor([[ 0.0822,  0.0459,  0.5809,  0.4871,  0.5112,  0.5887],\n",
      "        [-0.3669, -0.4167, -0.2044,  0.1982, -0.1030, -0.0816],\n",
      "        [ 0.6393,  0.5874, -0.3218, -0.1948, -0.4631, -0.5267],\n",
      "        [-0.0878,  0.1738, -0.0481, -0.2151, -0.0245,  0.0288]])\n",
      "Log odds: -4.092745575020835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Deduplicate sequences and show summary\n",
    "unique = {}\n",
    "for i, seq in enumerate(all_sequences):\n",
    "    if seq not in unique:\n",
    "        unique[seq] = i  # store first occurrence index\n",
    "\n",
    "unique_indices = list(unique.values())\n",
    "print(f\"Total sequences collected: {len(all_sequences)}\")\n",
    "print(f\"Number of unique sequences: {len(unique_indices)}\")\n",
    "\n",
    "# Print heads of each\n",
    "print(\"\\nFirst 5 unique sequences:\")\n",
    "for idx in unique_indices[:5]:\n",
    "    print(f\"Sequence: {all_sequences[idx]}\")\n",
    "    print(f\"Residual: {all_residuals[idx]}\")\n",
    "    print(f\"Log odds: {all_passive_logodds[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max log odds: 4.8012\n",
      "Min log odds: -4.7861\n",
      "Sequence for max log odds: ('R', 'R', 'R', 'R', 'R', 'R')\n",
      "Sequence for min log odds: ('L', 'L', 'L', 'L', 'L', 'L')\n"
     ]
    }
   ],
   "source": [
    "# 6. Find sequences with max and min log odds\n",
    "logodds_array = np.array(all_passive_logodds)\n",
    "max_idx = np.argmax(logodds_array)\n",
    "min_idx = np.argmin(logodds_array)\n",
    "\n",
    "print(f\"Max log odds: {logodds_array[max_idx]:.4f}\")\n",
    "print(f\"Min log odds: {logodds_array[min_idx]:.4f}\")\n",
    "print(f\"Sequence for max log odds: {all_sequences[max_idx]}\")\n",
    "print(f\"Sequence for min log odds: {all_sequences[min_idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2: 0.9701\n",
      "\n",
      "First 5 test predictions:\n",
      "Sequence: ('r', 'r', 'r', 'r', 'r', 'L')\n",
      "Predicted: -3.2829, True: -2.8225\n",
      "\n",
      "Sequence: ('r', 'r', 'R', 'r', 'R', 'R')\n",
      "Predicted: 3.6319, True: 4.1078\n",
      "\n",
      "Sequence: ('l', 'L', 'l', 'L', 'l', 'l')\n",
      "Predicted: -1.4295, True: -1.4037\n",
      "\n",
      "Sequence: ('l', 'l', 'r', 'l', 'l', 'l')\n",
      "Predicted: -0.6930, True: -0.7725\n",
      "\n",
      "Sequence: ('L', 'r', 'R', 'R', 'r', 'R')\n",
      "Predicted: 2.8983, True: 3.5332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Train linear regression: residual last column -> passive log odds\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1. Get unique indices, shuffle, and split\n",
    "unique_indices = list(unique.values())\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_indices)\n",
    "n_test = len(unique_indices) // 4\n",
    "test_indices = unique_indices[:n_test]\n",
    "train_indices = unique_indices[n_test:]\n",
    "\n",
    "# 2. Prepare X (features) and y (targets)\n",
    "def get_features_targets(indices):\n",
    "    X = []\n",
    "    y = []\n",
    "    for idx in indices:\n",
    "        # Residual: shape [n_embd, seq_len], take last column\n",
    "        X.append(all_residuals[idx][:, -1].cpu().numpy())\n",
    "        # Passive log odds: scalar value\n",
    "        y.append(all_passive_logodds[idx])\n",
    "    X = np.stack(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = get_features_targets(train_indices)\n",
    "X_test, y_test = get_features_targets(test_indices)\n",
    "\n",
    "# 3. Train linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict and evaluate\n",
    "y_pred = reg.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test R^2: {r2:.4f}\")\n",
    "\n",
    "# 5. Print a few predictions vs. true values with sequences\n",
    "print(f\"\\nFirst 5 test predictions:\")\n",
    "for i in range(5):\n",
    "    idx = test_indices[i]\n",
    "    print(f\"Sequence: {all_sequences[idx]}\")\n",
    "    print(f\"Predicted: {y_pred[i]:.4f}, True: {y_test[i]:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
